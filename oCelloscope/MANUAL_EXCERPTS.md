# 2015 version
...

GKA analysis on data acquired with Acquire Type set to "Reduced data" or "Minimal data" is more sensitive to minor disturbances than analysis where Acquire Type has been set to "Full data". This may for negative controls (scan areas containing only medium) in some situations result in negative growth curves. This can safely be ignored. In any case, the image data may be used to verify that there has been no growth.

## 6.1.1 Background Corrected Absorption

The Background Corrected Absorption (BCA) algorithm is designed to detect microbial growth with high sensitivity even at very low or high cell concentrations.

Based on the first image, the BCA algorithm corrects background intensities to obtain images with an even light distribution before calculating a threshold pixel value which divide pixels into 'background pixels' and 'object pixels'. The BCA algorithm generates growth curves based on changes in 'object pixels'. In this way, BCA is able to determine microbial growth with high sensitivity as the effect of background intensities are reduced significantly compared to the TA algorithm.

### Limitation:

BCA may lead to inaccurate determination of growth curves when for example condensation obscures light transmission resulting in darker images and consequently in false 'object pixels'.

The BCA algorithm has two steps:

- Correction of illumination profile
- Calculation of absorption by summarising pixel histogram content above a threshold

The BCA output is calculated as:

\[
\text{BCA} = \log_{10} (\text{corrected absorption pixel histograms})
\]

### BCA Norm
BCA Norm is computed in the same way as BCA except that the value of the first image is subtracted from the following images on the growth curve. BCA Norm growth curves are calculated for each individual scan area and will always start at point 0 independent of the initial cell concentration.

---

### 6.1.2 SEAL
The Segmentation and Extraction of Average Length (SEAL) algorithm measures the average object length in micrometers. The algorithm is designed to detect filamentous rod-shaped bacteria. The SEAL algorithm determines the mean bacterial length based on segmentation extraction of the average bacteria length.

#### Limitation:
SEAL is limited at high cell concentrations and may lead to inaccurate determination of filamentation when bacteria are overlapping.

SEAL only calculates values when the Acquire type is set to Minimal or Reduced data.

---

### SEAL Normalized
SEAL Norm is computed in the same way as SEAL except that the value of the first image is subtracted from the following images on the growth curve. SEAL Norm curves are calculated for each individual scan area and will always start at point 0 independent of the initial average length of bacterial cells.

---

### 6.1.3 SESA
The Segmentation and Extraction of Surface Area (SESA) algorithm measures microbial growth with high sensitivity and is robust to changes in light intensities caused by, for example, condensation.

The SESA algorithm determines microbial growth based on segmentation and contrast-based identification of all objects in a scan area. Growth curves are generated by summarizing the surface area covered by all identified objects in a scan area. Because growth curves are based on segmentation, the SESA algorithm is able to measure microbial growth with high accuracy even at very low cell concentrations and should not be affected by changes in illumination.

The SESA output is calculated as:

\[
\text{SESA} = \log_{10} (\text{covered surface area})
\]

Covered surface area = Area of identified objects (in pixels)

---

To identify the objects to include, the SESA feature performs an object segmentation with fixed segmentation parameters. In practice, this creates a scale from 0 (1) object/image to 6.7 (all objects in an image of 1920 × 2560 pixels).

### Limitation:
- SESA is limited at high cell concentrations and may lead to inaccurate measurement of growth curves when cells are overlapping. In general, the accuracy of SESA will begin to decline when objects cover more than 20% of the total image area. This means that a **SESA value of >6 is not reliable**.

- **SESA Norm** is computed in the same way as SESA except that the value of the first image is subtracted from the following images on the growth curve. SESA Norm growth curves are calculated for each individual scan area and will always start at point 0 independently of the initial cell concentration.

---

### 6.1.4 Total Absorption
The Total Absorption (TA) algorithm is a simple absorption measurement, which is comparable to conventional used turbidity methods.

TA growth curves are based on pixel values of the whole image where a bright image is equivalent to a low TA value and a dark image is equivalent to a high TA value. During microbial growth, the increasing number of microbial objects will reduce light transmission and the image will become darker and darker.

#### Limitation:
- TA is not very sensitive in case of low cell concentrations or at slow growth rates (for example, during lag and stationary phases) as microbial growth will only affect a few pixels at a time compared to the total pixel number of the image. Hence, TA should preferably be used for measurement of microbial growth in the exponential phase as growth and cell concentration need to be quite considerable before affecting the overall light intensity.

- The TA feature is sensitive to changes in the background intensity, which may be caused by e.g. condensation or dirt.

---

**TA Norm** is computed in the same way as TA except that the value of the first image is subtracted from the following images on the growth curve. TA Norm growth curves are calculated for each individual scan area and will always start at point 0 independently of the initial cell concentration.

---

### 6.2 Segmentation
The "Segmentation" task can be selected either in connection with the "Acquire" or the "Load" task. The segmentation process identifies all objects with certain characteristics in the recorded images.

...

## 6.2.7 Object Features
First you need to select which **object features** to calculate (see Figure 38).

The table below includes a technical description and some typical uses for each feature. This should help you to select the most feasible features for your sample.

Initially, a few illustrations are used to explain the background of some of the features calculated.

Figure 41 illustrates some of the standard geometric features calculated.

Figure 42 shows the process from a black and white object to a thinned image and an image skeleton, and furthermore illustrates **branch points**.

---

**Figure 41**: The object features explained in the example of a "pixelated" object.

- **Major Axis length**: 8
- **Minor Axis length**: 3
- **Perimeter**: 15.6
- **Area**: 20
- **Minimum Bounding Box**

---

**Figure 42**: The object features explained in the example of a "pixelated" object.

- **black/white image**
- **thinned image**
- **image skeleton**

---

## The available object features are:

| Feature     | Technical description                                                                                                                                                 | Typical use  |
|-------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------|
| **Area**    | The 'Area' algorithm measures the total number of pixels covered by an object (a pixel is approx. 0.55 µm x 0.55 µm = 0.3 µm²). The 'Area' value is not affected by object shape; e.g., objects with identical 'Area' values may have different shapes. 'Area' can be used to monitor changes in object size over time. The 'Area' algorithm is useful as a rough classifier to discriminate between different types of objects or to exclude irrelevant objects from the analysis based on their size. **Limitations**: The 'Area' algorithm may not be able to identify overlapping objects as individual objects. Hence, the 'Area' algorithm will in some cases identify and compute overlapping or clustering objects as one single object. See Figure 41. | General use  |
| **BranchPoints**   | 'BranchPoints' values are computed based on thinned images obtained by continuously removing pixels from the object boundary (without breaking the object apart) until only one pixel thick line or point remains. Using the thinned image, the 'BranchPoints' algorithm measures the number of branch points, i.e., object pixels with more than two adjacent object pixel neighbours. The 'BranchPoints' algorithm can be used to quantify the complexity of object shape. The more complex the shape is, the higher number of branch points the object has. See Figure 42. **Limitations**: The 'BranchPoints' algorithm may be limited by the presence of irrelevant objects that cover up or impair the detection of branch points, for example crystals in fermentation samples. At high cell concentrations, the algorithm may detect 'false' branch points in case of overlapping hyphae. | Ideal for monitoring of fungi and hyphae growth.           |
| **Circularity**    | The 'Circularity' algorithm measures how similar the object shape is to a circle independently of the object size; e.g., objects with identical shape but different in size will have the same 'Circularity' value. Calculated as the ratio between the perimeter of a circle with the same area as the object, and the perimeter of the object. Values range between 0 and 1. **Limitations**: The 'Circularity' algorithm may not be able to identify overlapping objects as individual objects. Hence, the 'Circularity' algorithm will in some cases identify and compute overlapping or clustering objects as one single object. | Ideal for detection of circular objects such as blood cells and cocci. |
| **CircularVariance** | The 'CircularVariance' algorithm measures how similar the object shape is to a circle (the degree of non-circularity). 'CircularVariance' values are computed by measuring the distance from the object centroid to each point on the object boundary followed by calculation of the variance of these distances. Circular objects like red blood cells and cocci will have a 'CircularVariance' value close to 0 whereas rectangular objects like filamentous bacteria and crystals will have a high 'CircularVariance' value; i.e., the 'CircularVariance' value increases as the object shape gets more complex. **Limitations**: The 'CircularVariance' algorithm may not be able to identify overlapping objects as individual objects. Hence, the 'CircularVariance' algorithm will in some cases identify and compute overlapping or clustering objects as one single object. | Ideal for discrimination of equal sized objects with different shape complexity. |
| **Compactness** | The 'Compactness' algorithm measures the ratio between the object area and the area of its convex image. 'Compactness' values are independent of object size and can be used to describe the complexity of object shape. Objects like cocci, red blood cells, and crystals have a high 'Compactness' value whereas clusters of objects and multiploid yeast cells have a low 'Compactness' value. Calculated as the ratio between the object area (blue in figure) and the area of its convex image (red in figure). Values between 0 and 1. **Limitations**: The 'Compactness' algorithm may not be able to identify overlapping objects as individual objects. Hence, the 'Compactness' algorithm will in some cases identify and compute overlapping or clustering objects as one single object. | General use. Useful for monitoring of, for example, budding yeast. |
| **Contrast**     | The 'Contrast' algorithm measures the ratio between the mean object intensity and the mean background intensity, e.g., how light is attenuated by an object. Dark objects on a bright background will have a positive 'Contrast' value whereas bright objects on a dark background will result in a negative 'Contrast' value. Measurement of 'Contrast' values is independent of object size.                                                                                                                                  | General use. Useful for differentiation between objects with different absorption.          |
| **Elongation**   | The 'Elongation' algorithm measures stretching of objects. The algorithm is useful for several applications, for example monitoring of cellular elongation (e.g., antimicrobial-induced filamentation) and identification of rectangular or oval objects such as casts in urine samples and crystals in fermentation samples. 'Elongation' is computed by fitting an ellipse to the object shape followed by measuring the ratio of the minor and the major axis. 'Elongation' values vary from 0 to 1. A rectangular or oval object will have a low 'Elongation' value whereas a circular or square object will have a high 'Elongation' value. Since the algorithm is designed to fit an ellipse, curved elongated objects may result in almost circular ellipses and thereby high 'Elongation' values although the objects are significantly elongated. See Figure 41. **Limitations**: The algorithm should not be used to monitor cellular elongation in case of curved or asymmetric cell shapes. The 'Elongation' algorithm may not be able to identify overlapping objects as individual objects. Hence, the 'Elongation' algorithm will in some cases identify and compute overlapping or clustering objects as one single object. | Ideal for detection of crystals and casts or monitoring of straight-rod cellular elongation. |
| **Granularity**  | The 'Granularity' algorithm measures the intensity homogeneity of an object; e.g., different types or stages of mammalian cells can be classified based on their granular content. For example, T and B lymphocytes with a relative uniform intensity will result in different 'Granularity' values compared to mast cells with heterogeneous intensity because of their high content of granules.                                                   | Ideal for differentiation and classification of mammalian cells.                 |
| **IntensityMax** | The 'IntensityMax' algorithm measures the difference between the maximum object intensity and the mean background intensity. 'IntensityMax' values are computed for individual objects by subtracting the mean background intensity from the highest object intensity value. **Limitations**: The 'IntensityMax' algorithm is sensitive to pixel noise.                                                                                                                                               | Useful for differentiation between objects based on their intensity pattern.     |
| **IntensityMean** | The 'IntensityMean' algorithm measures the difference between the mean object intensity and the mean background intensity. 'IntensityMean' values are computed for individual objects by subtracting the mean background intensity from mean object intensities. Intensities are scaled from 0 to 255, hence this value is between -255 and 255. Dark objects on a bright background will result in negative 'IntensityMean' values, whereas bright objects on a dark background result in positive 'IntensityMean' values. As a supplementary feature, the 'IntensityMean' algorithm is very useful for improvement of classification of objects based on differences in absorption. | Useful for differentiation between objects with different absorption.            |
| **IntensityMedian** | The 'IntensityMedian' algorithm measures the difference between the median object intensity and the mean background intensity. 'IntensityMedian' values are computed for individual objects by subtracting the mean background intensity from median object intensity. Dark objects on a lighter background will result in negative 'IntensityMedian' values, whereas bright objects on a darker background result in positive 'IntensityMedian' values. As a supplementary feature, the 'IntensityMedian' algorithm is very useful for improvement of classification of objects based on differences in absorption. | Useful for differentiation between objects with different absorption.            |
| **IntensityMin** | The 'IntensityMin' algorithm measures the difference between the minimum object intensity and the mean background intensity. 'IntensityMin' values are computed for individual objects by subtracting the mean background intensity from the lowest object intensity value. **Limitations**: The 'IntensityMin' algorithm is sensitive to pixel noise.                                                                                                                                                     | Useful for differentiation between objects based on their intensity pattern.     |
| **IntensitySTD** | The 'IntensitySTD' algorithm measures the intensity homogeneity for individual objects. Objects with a uniform intensity distribution such as red blood cells and cocci will result in low 'IntensitySTD' values, whereas objects with a heterogeneous intensity pattern such as granular cells and cell clusters will result in high 'IntensitySTD' values.                                                                                                                                               | Useful for differentiation based on their absorption pattern.                    |
| **MirrorSymmetry** | The 'MirrorSymmetry' algorithm computes the degree of object mirror symmetry by measuring the orientation of aligned linear edges. Symmetric objects with distinct linear edges such as rod-shaped bacteria and rectangular crystals will have a high 'MirrorSymmetry' value (above 3.5). Non-symmetric objects such as budding yeast and objects without linear edges like circular bacterial cocci and quadratic crystals will have low 'MirrorSymmetry' values (0 to 2.5). **Limitations**: The 'MirrorSymmetry' algorithm may not be able to identify overlapping objects as individual objects. Hence, the 'MirrorSymmetry' algorithm will in some cases identify and compute overlapping or clustering objects as one single object. | Ideal for detection and classification of symmetric elongated objects such as rectangular crystals and rod-shaped bacteria. |
| **MomentGray**     | The 'MomentGray' values are computed based on how much object intensities are correlated in the two orthogonal directions. 'MomentGray' values are independent of whether objects appear brighter or darker compared to the background, e.g., identical objects will have similar 'MomentGray' values, regardless of if they are in focus or out of focus. 'MomentGray' values are between 0 and 1, where a value of 1 is produced by a circle with identical intensity of all pixels. Circular objects such as cocci and red blood cells will result in low 'MomentGray' values, whereas elongated objects such as rod-shaped bacteria will result in high 'MomentGray' values. **Limitations**: The 'MomentGray' algorithm may not be able to identify overlapping objects as individual objects. Hence, the 'MomentGray' algorithm will in some cases identify and compute overlapping or clustering objects as one single object. | Ideal for identification of objects with characteristic shapes and filamentous bacteria.                     |
| **Perimeter**      | The 'Perimeter' algorithm measures the object perimeter and can be used to discriminate between objects with equivalent areas, but with different shapes. 'Perimeter' values are computed based on the distance of the object border. Large objects will result in a higher 'Perimeter' value than small objects. The shape will affect 'Perimeter' value in cases of objects possessing identical areas; e.g., a circular object has a lower value than objects with any other shape. See Figure 41. **Limitations**: The 'Perimeter' algorithm may not be able to identify overlapping objects as individual objects. Hence, the 'Perimeter' algorithm will in some cases identify and compute overlapping or clustering objects as one single object. | Ideal for monitoring of budding yeast cells and for classification of objects with identical sizes (areas) but with different shapes. |
| **Rectangularity** | The 'Rectangularity' algorithm measures how similar the object shape is to a rectangle. 'Rectangularity' values are computed by fitting a minimum bounding rectangle before measuring the ratio between the object area and the area of its fitted minimum bounding rectangle. See Figure 41. Objects like crystals and casts will have a high 'Rectangularity' value compared to circular shaped objects (for example blood cells). **Limitations**: The 'Rectangularity' algorithm may not be able to identify overlapping objects as individual objects. Hence, the 'Rectangularity' algorithm will in some cases identify and compute overlapping or clustering objects as one single object. | Ideal for identification of rectangular objects such as crystals and casts.                     |
| **SkeletonLength** | 'SkeletonLength' values are computed based on thinned images obtained by continuously removing pixels from the object boundary (without breaking the object apart) until only one pixel thick line or point remains. Using the thinned image, the 'SkeletonLength' algorithm measures the length of individual objects as the sum of skeleton pixels. See Figure 42. **Limitations**: The 'SkeletonLength' algorithm may not be able to identify overlapping objects as individual objects. Hence, the 'SkeletonLength' algorithm will in some cases identify and compute overlapping or clustering objects as one single object and thereby overestimate for example hyphae length. | Ideal for monitoring of fungi and hyphae growth.                                               |
| **Squareness**     | The 'Squareness' algorithm measures how similar the object shape is to a square. 'Squareness' values are computed by fitting a minimum bounding rectangle before measuring the ratio between the shortest and longest sides of the fitted rectangle. Objects with the same axis ratio will result in equal 'Squareness' values; e.g., a square shaped crystal will have the same value as a circular blood cell. **Limitations**: The 'Squareness' algorithm may not be able to identify overlapping objects as individual objects. Hence, the 'Squareness' algorithm will in some cases identify and compute overlapping or clustering objects as one single object. | General use. Useful for identification of crystals and discrimination between cocci and rod-shaped bacteria. |
| **ThinnedLength**  | 'ThinnedLength' values are computed based on thinned images obtained by continuously removing pixels from the object boundary (without breaking the object apart) until only one pixel thick line or point remains. Using the thinned image, the 'ThinnedLength' algorithm measures the length of an object. See Figure 42. **Limitations**: The 'ThinnedLength' algorithm may not be able to identify overlapping objects as individual objects. Hence, the 'ThinnedLength' algorithm will in some cases identify and compute overlapping or clustering objects as one single object and thereby overestimate for example hyphae length. | Ideal for monitoring of fungi and hyphae growth.                                               |

# 2020 version

...

## 5.2 Segmentation

The "Segmentation" task can be selected either in connection with the "Acquire" or "Load" task. The segmentation process detects all objects with certain characteristics in the recorded images.

### 5.2.1 Object Features

First you need to select which **object features** to calculate (see Figure 38) for the detected objects.

The table below includes a technical description and some typical uses for each feature. This should help you to select the most feasible features for your sample.

Initially a few illustrations are used to explain the background of some of the features calculated.

Figure 41 illustrates some of the standard geometric figures calculated.

---

### The available object features are:

| Feature             | Technical description                                                                                                                                                                                                                                                                                                                                                                                       | Typical use  |
|---------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------|
| **Area**            | The 'Area' algorithm measures the total number of pixels covered by an object (a pixel is approx. 0.55 μm x 0.55 μm = 0.3 μm²). The 'Area' value is not affected by object shape; e.g., objects with identical 'Area' values may have different shapes. 'Area' can be used to monitor changes in object size over time. The 'Area' algorithm is useful as a rough classifier to discriminate between different types of objects or to exclude irrelevant objects from the analysis based on their size. ISO 9276-6. | General use  |
| **AspectRatio**     | The 'AspectRatio' algorithm measures the ratio between the 'FeretMin' and 'FeretMax'. ISO 9276-6.                                                                                                                                                                                                                                                                                                          | General use  |
| **AverageConcavity** | The 'AverageConcavity' algorithm measures the ratio between 'FeretMean' and the 'Perimeter'. ISO 9276-6.                                                                                                                                                                                                                                                                                                  | General use  |
| **AvgThickness**  | The 'AvgThickness' algorithm measures the average geodesic thickness (red arrows) along the thinned image (black line) of elongated objects in pixels. <br><br>![Image](ISO 9276-6)                                                                                                                                                        | Useful for monitoring of fungi and hyphae growth.                         |
| **BranchPoints**  | 'BranchPoints' values are computed based on thinned image (black line). The 'BranchPoints' algorithm measures the number of branch points, i.e., object pixels with more than two adjacent object pixel neighbors (red circle). <br><br>![Image](ISO 9276-6)                                                                              | Useful for monitoring of fungi and hyphae growth.                         |
| **BrightSpots**   | The 'BrightSpots' algorithm counts the number of yeast cells in strings of connected budding cells. <br><br>**Limitation:** To get a correct result you have to choose and analyze a bright phase z-layer image, where the cytoplasm is imaged as white.                                              | Useful for differentiation between single yeast cells and budding yeast cells. |
| **Circularity**   | The 'Circularity' algorithm measures how similar the object shape is to a circle independently of the object size; e.g., objects with identical shape but different in size will have the same 'Circularity' value. <br><br>Calculated as the ratio between the perimeter of a circle with the same area as the object, and the perimeter of the object. Values between 0 and 1. <br><br>![Image](ISO 9276-6) | General use                                                               |
| **Contrast**      | The 'Contrast' algorithm measures the ratio between the mean object intensity and the mean background intensity, e.g., how light is attenuated by an object. <br><br>Dark objects on a bright background will have a positive 'Contrast' value whereas bright objects on a dark background will result in a negative 'Contrast' value. Measurement of 'Contrast' values is independent of object size. | Useful for differentiation between objects with different absorption.     |
| **Convexity**    | The 'Convexity' algorithm measures the compactness of an object. The 'Convexity' is calculated as a ratio between the object 'Perimeter' (blue in figure) and the perimeter of the convex hull (red envelope in figure) bounding the object. <br><br>![Image](ISO 9276-6)                                                                             | General use                                                           |
| **EllipseRatio** | The 'EllipseRatio' algorithm measures the ratio between the minor axis length and major axis length of the ellipse with its center at the particle’s centroid and the same geometrical moments as the original particle. <br><br>An ellipse whose 'EllipseRatio' is 0 is a circle, while an ellipse whose 'EllipseRatio' is 1 is a line segment. <br><br>![Image](ISO 9276-6) | General use monitoring straight-rod cell elongation                   |
| **Elongation**   | The 'Elongation' algorithm measures stretching of objects by calculating the ratio between 'AvgThickness' and 'LongestPath'. <br><br>![Image](ISO 9276-6)                                                                                                                                                                                           | Useful for monitoring of fungi and hyphae growth                      |
| **EQPC**         | The 'EQPC' algorithm measures the diameter of a circle having the same projection area as the object. The 'EQPC' value is measured in pixels. <br><br>![Image](ISO 9276-6)                                                                                                                                                                          | Evaluation of particles with different sizes of a non-spherical particle |
| **Feret Diameters (Feret min, Feret max, Feret mean)** | The Feret diameters are a group of diameters derived from the distance of two tangents to the contour of the object in all angles. If a particle has an irregular shape, the Feret diameter varies more than with regularly shaped objects. The maximum Feret diameter is always larger than the diameter of the equivalent circle ‘EQPC’. <br><br> The ‘FeretMin’ algorithm measures the minimum distance between two parallel tangents of the object at an arbitrary angle. <br> The ‘FeretMax’ algorithm measures the maximum distance between two parallel tangents of the object at an arbitrary angle. <br> The ‘FeretMean’ algorithm measures the angle-average Feret diameter of the object. <br><br> **Reference**: ISO 9276-6 | General use |
| **IntensityMax** | The ‘IntensityMax’ algorithm measures the difference between the maximum object intensity and the mean background intensity. ‘IntensityMax’ values are computed for individual objects by subtracting the mean background intensity from the highest object intensity value. <br><br> **Limitations**: The ‘IntensityMax’ algorithm is sensitive to pixel noise. | Useful for differentiation between objects based on their intensity pattern. |
| **IntensityMin** | The ‘IntensityMin’ algorithm measures the difference between the minimum object intensity and the mean background intensity. ‘IntensityMin’ values are computed for individual objects by subtracting the mean background intensity from the lowest object intensity value. <br><br> **Limitations**: The ‘IntensityMin’ algorithm is sensitive to pixel noise. | Useful for differentiation between objects based on their intensity pattern. |
| **Irregularity** | The ‘Irregularity’ algorithm measures the relationship between the diameter of the maximum inscribed circle and the minimum circumscribed circle of an object. <br><br> **Reference**: ISO 9276-6 | General use |
| **LongestPath** | The ‘LongestPath’ algorithm measures the length of the longest geodesic path of elongated objects such as fungi hyphae or fibers. <br><br> The ‘LongestPath’ of a fungi hypha is defined as the direct connection between its opposite ends; this is the longest direct path from one end to another within the object. Direct means without loops or deviations. If a hypha has branches, the algorithm selects the longest one (red in figure). <br><br> **Reference**: ISO 9276-6 | Useful for monitoring of fungi and hyphae growth |
| **Perimeter** | The ‘Perimeter’ algorithm measures the total number of pixels in the object border. <br><br> The object shape will affect ‘Perimeter’ value in cases of objects possessing identical areas; e.g., a circular object has a lower value than objects with any other shape. <br><br> **Reference**: ISO 9276-6 | General use |
| **TotalLength** | The ‘TotalLength’ algorithm measures the total geodesic length of elongated objects such as fungi hyphae or fibers. <br><br> The ‘TotalLength’ is measured in pixels and is calculated as a sum of all object components including length of branches (red in figure). <br><br> **Reference**: ISO 9276-6 | Useful for monitoring of fungi and hyphae growth |

When the segmentation features are selected, press the "Next" button.

## 5.2.2 Segmentation Setup

When features have been selected and "Next" pressed, a pre-scan will be performed on the first scan area. UniExplorer will choose the layer with the best focus, but you can change this by selecting another layer as indicated by the red box in Figure 42.

![Figure 42: The Segmentation Setup window.](#)

The Segmentation setup window is used to tune the segmentation to detect the right objects. This is done by selecting the relevant segmentation algorithm and tuning various parameters, and it is possible to test if the right objects are detected. Settings can be changed until you are satisfied with the detection results.

In the Segmentation setup window, the first option is to choose the algorithm to use for identifying the objects:

- **Hmin (default)**  
  This algorithm detects objects based on contrast differences.  
  Use this algorithm for compact objects like bacteria and blood cells.

- **FungiHmin**  
  This algorithm detects objects similar to Hmin but is used with fungi which can be bright/transparent.

- **Gradient**  
  This algorithm detects objects based on edge magnitudes.  
  Use this algorithm for phase objects like yeast cells and clusters.

When the algorithm has been selected you should test the effect of the current settings by pressing the "Test Settings" button (see Figure 43). The currently detected objects are marked with red borders.

You can zoom the image by scrolling the mouse wheel, and you can pan the image (when zoomed) by holding down the right mouse button.
